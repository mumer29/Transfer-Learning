{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.models as models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# CIFAR-10 transform for pretrained models (normalize to ImageNet stats)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Most models expect 224x224\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model(base_model, num_classes=10):\n    for param in base_model.parameters():\n        param.requires_grad = False  # Freeze base\n\n    if hasattr(base_model, 'fc'):  # For ResNet\n        in_features = base_model.fc.in_features\n        base_model.fc = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(256, num_classes)\n        )\n    elif hasattr(base_model, 'classifier'):\n        in_features = base_model.classifier[-1].in_features if isinstance(base_model.classifier, nn.Sequential) else base_model.classifier.in_features\n        base_model.classifier = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(256, num_classes)\n        )\n    return base_model.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, trainloader, testloader, epochs=5, fine_tune=False):\n    if fine_tune:\n        for param in model.parameters():\n            param.requires_grad = True  # Unfreeze all for fine-tuning\n    \n    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        model.train()\n        for inputs, labels in trainloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    # Evaluate\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n  0%|          | 0.00/528M [00:00<?, ?B/s]\n  2%|▏         | 12.9M/528M [00:00<00:04, 135MB/s]\n  5%|▌         | 28.8M/528M [00:00<00:03, 153MB/s]\n  8%|▊         | 44.6M/528M [00:00<00:03, 159MB/s]\n 11%|█▏        | 59.9M/528M [00:00<00:03, 155MB/s]\n 14%|█▍        | 75.9M/528M [00:00<00:02, 159MB/s]\n 17%|█▋        | 92.1M/528M [00:00<00:02, 163MB/s]\n 21%|██        | 108M/528M [00:00<00:02, 165MB/s] \n 24%|██▎       | 124M/528M [00:00<00:02, 165MB/s]\n 27%|██▋       | 140M/528M [00:00<00:02, 165MB/s]\n 30%|██▉       | 156M/528M [00:01<00:02, 165MB/s]\n 33%|███▎      | 172M/528M [00:01<00:02, 165MB/s]\n 36%|███▌      | 188M/528M [00:01<00:02, 161MB/s]\n 38%|███▊      | 203M/528M [00:01<00:02, 158MB/s]\n 41%|████▏     | 219M/528M [00:01<00:02, 160MB/s]\n 45%|████▍     | 236M/528M [00:01<00:01, 166MB/s]\n 48%|████▊     | 253M/528M [00:01<00:01, 170MB/s]\n 51%|█████     | 270M/528M [00:01<00:01, 172MB/s]\n 54%|█████▍    | 287M/528M [00:01<00:01, 174MB/s]\n 58%|█████▊    | 304M/528M [00:01<00:01, 176MB/s]\n 61%|██████    | 321M/528M [00:02<00:01, 175MB/s]\n 64%|██████▍   | 338M/528M [00:02<00:01, 173MB/s]\n 67%|██████▋   | 354M/528M [00:02<00:01, 172MB/s]\n 70%|███████   | 371M/528M [00:02<00:00, 171MB/s]\n 73%|███████▎  | 387M/528M [00:02<00:00, 170MB/s]\n 76%|███████▋  | 404M/528M [00:02<00:00, 169MB/s]\n 80%|███████▉  | 420M/528M [00:02<00:00, 168MB/s]\n 83%|████████▎ | 436M/528M [00:02<00:00, 165MB/s]\n 86%|████████▌ | 452M/528M [00:02<00:00, 166MB/s]\n 89%|████████▊ | 468M/528M [00:02<00:00, 166MB/s]\n 92%|█████████▏| 484M/528M [00:03<00:00, 166MB/s]\n 95%|█████████▍| 500M/528M [00:03<00:00, 166MB/s]\n 98%|█████████▊| 516M/528M [00:03<00:00, 166MB/s]\n100%|██████████| 528M/528M [00:03<00:00, 166MB/s]\n\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.tolist())\n            y_pred.extend(preds.cpu().tolist())\n\n    acc = accuracy_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    return acc, cm, y_true, y_pred\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pretrained_models = {\n    \"ResNet50\": models.resnet50(weights='IMAGENET1K_V1'),\n    \"MobileNetV2\": models.mobilenet_v2(weights='IMAGENET1K_V1'),\n    \"EfficientNet_B0\": models.efficientnet_b0(weights='IMAGENET1K_V1'),\n    \"VGG16\": models.vgg16(weights='IMAGENET1K_V1'),\n    \"DenseNet121\": models.densenet121(weights='IMAGENET1K_V1'),\n}\n\nresults = {}\n\nfor name, base_model in pretrained_models.items():\n    print(f\"\\n--- {name} ---\")\n    model = create_model(base_model)\n    \n    acc_frozen, cm_frozen, y_true, y_pred = train_model(model, trainloader, testloader, epochs=3, fine_tune=False)\n    acc_finetuned, cm_finetuned, _, _ = train_model(model, trainloader, testloader, epochs=3, fine_tune=True)\n\n    results[name] = {\n        \"Before FT Accuracy\": acc_frozen,\n        \"After FT Accuracy\": acc_finetuned,\n        \"Confusion Matrix Before\": cm_frozen,\n        \"Confusion Matrix After\": cm_finetuned,\n        \"y_true\": y_true,\n        \"y_pred\": y_pred\n    }\n\n    print(f\"Accuracy Before Fine-Tuning: {acc_frozen:.4f}\")\n    print(f\"Accuracy After Fine-Tuning: {acc_finetuned:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_conf_matrix(cm, title):\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=trainset.classes)\n    disp.plot(cmap='Blues', xticks_rotation=45)\n    plt.title(title)\n    plt.show()\n\n# Plot for each model\nfor model_name, data in results.items():\n    plot_conf_matrix(data[\"Confusion Matrix Before\"], f\"{model_name} - Before Fine-Tuning\")\n    plot_conf_matrix(data[\"Confusion Matrix After\"], f\"{model_name} - After Fine-Tuning\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    #\"Simple CNN\": SimpleCNN(),\n     \"Deeper CNN\": DeeperCNN(),\n    # \"Dropout CNN\": DropoutCNN(),\n    # \"BatchNorm CNN\": BatchNormCNN(),\n    # \"Augmented CNN\": AugmentCNN(),\n}\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name}\")\n    train_loss, test_loss, train_acc, test_acc = train_model(model, trainloader, testloader)\n    plot_curves(train_acc, test_acc, train_loss, test_loss, name)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}